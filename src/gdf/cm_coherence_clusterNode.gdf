# --- GDF Version History ---
# 1.0 - Initial version
# 2.0 - Change done for match Long_data and Long_long_data to double
# 3.0 - Changes done for Dynamic data in Execution GUI
# 3.1 - Use future1 field of group line for Metric group name
Info|3.1|1|-|-|-1|-1|-
Group|Coherence Mbean ClusterNode Data|10032|vector|20|0|Application Metrics|Tier>Server>ClusterName>Instance|Information related to Coherence ClusterNodeData

#Graph|BufferPublishSize|1|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The buffer size of the unicast datagram socket used by the Publisher, measured in the number of packets. Changing this value at runtime is an inherently unsafe operation that will pause all network communications and may result in the termination of all cluster services.
#Graph|BufferReceiveSize|2|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The buffer size of the unicast datagram socket used by the Receiver, measured in the number of packets. Changing this value at runtime is an inherently unsafe operation that will pause all network communications and may result in the termination of all cluster services.
#Graph|BurstCount|3|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The maximum number of packets to send without pausing. Anything less than one (e.g. zero) means no limit.
#Graph|BurstDelay|4|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of milliseconds to pause between bursts. Anything less than one (e.g. zero) is treated as one millisecond.
#Graph|CpuCount|5|scalar|sample|-|-|0|NA|-1|-1|NA|NA|Number of CPU cores for the machine this Member is running on.
#Graph|Id|6|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The short Member id that uniquely identifies the Member at this point in time and does not change for the life of this Member.
#Graph|LoggingLevel|7|scalar|sample|-|-|0|NA|-1|-1|NA|NA|Specifies which logged messages will be output to the log destination. Valid values are non-negative integers or -1 to disable all logger output.
#Graph|LoggingLimit|8|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The maximum number of characters that the logger daemon will process from the message queue before discarding all remaining messages in the queue. Valid values are integers in the range [0...]. Zero implies no limit.
#Graph|MachineId|9|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The Member`s machine Id.
Graph|MemoryAvailableMB|10|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The total amount of memory in the JVM available for new objects in MB.
Graph|MemoryMaxMB|11|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The maximum amount of memory that the JVM will attempt to use in MB.
#Graph|MulticastPort|12|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The port of the Member`s MulticastSocket for group communication.
#Graph|MulticastTTL|13|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The time-to-live for multicast packets sent out on this Member`s MulticastSocket.
#Graph|MulticastThreshold|14|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The percentage (0 to 100) of the servers in the cluster that a packet will be sent to, above which the packet will be multicasted and below which it will be unicasted.
Graph|NackSent|15|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The total number of NACK packets sent since the node statistics were last reset.
Graph|PacketDeliveryEfficiency|16|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The efficiency of packet loss detection and retransmission. A low efficiency is an indication that there is a high rate of unnecessary packet retransmissions.
Graph|PacketsBundled|17|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The total number of packets which were bundled prior to transmission. The total number of network transmissions is equal to (PacketsSent - PacketsBundled).
Graph|PacketsReceived|18|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of packets received since the node statistics were last reset.
Graph|PacketsRepeated|19|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of duplicate packets received since the node statistics were last reset.
Graph|PacketsResent|20|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of packets resent since the node statistics were last reset. A packet is resent when there is no ACK received within a timeout period.
Graph|PacketsResentEarly|21|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The total number of packets resent ahead of schedule. A packet is resent ahead of schedule when there is a NACK indicating that the packet has not been received.
Graph|PacketsResentExcess|22|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The total number of packet retransmissions which were later proven unnecessary.
Graph|PacketsSent|23|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of packets sent since the node statistics were last reset.
#Graph|Priority|24|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The priority or weight of the Member; used to determine tie-breakers.
Graph|PublisherPacketUtilization|25|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The publisher packet utilization for this cluster node since the node socket was last reopened. This value is a ratio of the number of bytes sent to the number that would have been sent had all packets been full. A low utilization indicates that data is not being sent in large enough chunks to make efficient use of the network.
Graph|PublisherSuccessRate|26|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The publisher success rate for this cluster node since the node statistics were last reset. Publisher success rate is a ratio of the number of packets successfully delivered in a first attempt to the total number of sent packets. A failure count is incremented when there is no ACK received within a timeout period. It could be caused by either very high network latency or a high packet drop rate.
Graph|ReceiverPacketUtilization|27|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The receiver packet utilization for this cluster node since the socket was last reopened. This value is a ratio of the number of bytes received to the number that would have been received had all packets been full. A low utilization indicates that data is not being sent in large enough chunks to make efficient use of the network.
Graph|ReceiverSuccessRate|28|scalar|rate|-|-|0|NA|-1|-1|NA|NA|The receiver success rate for this cluster node since the node statistics were last reset. Receiver success rate is a ratio of the number of packets successfully acknowledged in a first attempt to the total number of received packets. A failure count is incremented when a re-delivery of previously received packet is detected. It could be caused by either very high inbound network latency or lost ACK packets.
#Graph|ResendDelay|29|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The minimum number of milliseconds that a packet will remain queued in the Publisher`s re-send queue before it is resent to the recipient(s) if the packet has not been acknowledged. Setting this value too low can overflow the network with unnecessary repetitions. Setting the value too high can increase the overall latency by delaying the re-sends of dropped packets. Additionally, change of this value may need to be accompanied by a change in SendAckDelay value.
#Graph|SendAckDelay|30|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The minimum number of milliseconds between the queueing of an Ack packet and the sending of the same. This value should be not more then a half of the ResendDelay value.
Graph|SendQueueSize|31|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of packets currently scheduled for delivery. This number includes both packets that are to be sent immediately and packets that have already been sent and awaiting for acknowledgment. Packets that do not receive an acknowledgment within ResendDelay interval will be automatically resent.
#Graph|SocketCount|32|scalar|sample|-|-|0|NA|-1|-1|NA|NA|Number of CPU sockets for the machine this Member is running on.
Graph|TcpRingFailures|33|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of recovered TcpRing disconnects since the node statistics were last reset. A recoverable disconnect is an abnormal event that is registered when the TcpRing peer drops the TCP connection, but recovers after no more then maximum configured number of attempts.This value will be -1 if the TcpRing is disabled.
Graph|TcpRingTimeouts|34|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of TcpRing timeouts since the node statistics were last reset. A timeout is a normal, but relatively rare event that is registered when the TcpRing peer did not ping this node within a heartbeat interval. This value will be -1 if the TcpRing is disabled.
Graph|TrafficJamCount|35|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The maximum total number of packets in the send and resend queues that forces the publisher to pause client threads. Zero means no limit.
Graph|TrafficJamDelay|36|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The number of milliseconds to pause client threads when a traffic jam condition has been reached. Anything less than one (e.g. zero) is treated as one millisecond.
#Graph|UnicastPort|37|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The port of the Member`s DatagramSocket for point-to-point communication.
#Graph|WeakestChannel|38|scalar|sample|-|-|0|NA|-1|-1|NA|NA|The id of the cluster node to which this node is having the most difficulty communicating, or -1 if none is found. A channel is considered to be weak if either the point-to-point publisher or receiver success rates are below 1.0.
